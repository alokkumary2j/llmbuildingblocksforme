{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=27\n",
    "head_size=4\n",
    "block_size=6# MAX POSSIBLE SEQ LENGTH\n",
    "n_embd=4\n",
    "class MyTorchModule(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        print(\"Tril Buffer \",self.tril)\n",
    "    def forward(self,token_seq):\n",
    "        x= self.token_embedding_table(token_seq)\n",
    "        T,C=x.shape # C is n_embd; T is current Sequence Length\n",
    "        print(\"Current Sequence Length \",T)\n",
    "        k=self.key(x) # (T, head_size)\n",
    "        q=self.query(x) # (T, head_size)\n",
    "        v=self.value(x) #(T, head_size)\n",
    "        print(\"Called Forward with Input \",x)\n",
    "        wei = q @ k.transpose(-2,-1) #Not doing any scaling here; Because the focus is just on KV-Caching\n",
    "        print(\"Weight = \", wei)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        print(\"Weight After Mask Filling \", wei)\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        print(\"Raw Values to Offer for Attention \",v)\n",
    "        print(\"Final Weights for Value Accumulation \",wei)\n",
    "        out = wei @ v #(T,T)@(T,head_size) => (T, head_size)\n",
    "        print(\"Accumulated Values for Attention  \", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tril Buffer  tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "attention_model=MyTorchModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Sequence Length  4\n",
      "Called Forward with Input  tensor([[-0.1114,  0.2369,  1.2289,  0.0469],\n",
      "        [ 1.1885,  0.8388,  0.4477, -1.8496],\n",
      "        [-1.3062,  0.8522, -0.7679,  1.1046],\n",
      "        [-1.3318,  0.5408,  0.4993,  0.5870]], grad_fn=<EmbeddingBackward0>)\n",
      "Weight =  tensor([[ 0.1432,  0.7684, -0.5193, -0.2819],\n",
      "        [-0.0383, -0.8364,  0.3031,  0.2034],\n",
      "        [ 0.0155,  0.8748, -0.3244, -0.2943],\n",
      "        [ 0.2540,  1.1855, -0.8233, -0.4735]], grad_fn=<MmBackward0>)\n",
      "Weight After Mask Filling  tensor([[ 0.1432,    -inf,    -inf,    -inf],\n",
      "        [-0.0383, -0.8364,    -inf,    -inf],\n",
      "        [ 0.0155,  0.8748, -0.3244,    -inf],\n",
      "        [ 0.2540,  1.1855, -0.8233, -0.4735]], grad_fn=<MaskedFillBackward0>)\n",
      "Raw Values to Offer for Attention  tensor([[ 0.6596, -0.3412,  0.6854,  0.4623],\n",
      "        [-0.3994,  0.1570,  0.5419,  0.6956],\n",
      "        [ 0.7482, -0.7134, -0.0972, -0.1077],\n",
      "        [ 0.9776, -0.8043,  0.2481,  0.1621]], grad_fn=<MmBackward0>)\n",
      "Final Weights for Value Accumulation  tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6896, 0.3104, 0.0000, 0.0000],\n",
      "        [0.2455, 0.5798, 0.1748, 0.0000],\n",
      "        [0.2293, 0.5819, 0.0781, 0.1108]], grad_fn=<SoftmaxBackward0>)\n",
      "Accumulated Values for Attention   tensor([[ 0.6596, -0.3412,  0.6854,  0.4623],\n",
      "        [ 0.3309, -0.1865,  0.6409,  0.5347],\n",
      "        [ 0.0611, -0.1174,  0.4655,  0.4980],\n",
      "        [ 0.0855, -0.1316,  0.4924,  0.5203]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "curr_token_seq= [10,12,24,3]\n",
    "ix= torch.tensor(curr_token_seq)\n",
    "attention_output1=attention_model(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Sequence Length  5\n",
      "Called Forward with Input  tensor([[-1.1140e-01,  2.3685e-01,  1.2289e+00,  4.6872e-02],\n",
      "        [ 1.1885e+00,  8.3883e-01,  4.4766e-01, -1.8496e+00],\n",
      "        [-1.3062e+00,  8.5220e-01, -7.6790e-01,  1.1046e+00],\n",
      "        [-1.3318e+00,  5.4085e-01,  4.9931e-01,  5.8696e-01],\n",
      "        [-4.0275e-04, -1.0988e+00, -5.7268e-01, -1.2227e+00]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Weight =  tensor([[ 0.1432,  0.7684, -0.5193, -0.2819,  0.0923],\n",
      "        [-0.0383, -0.8364,  0.3031,  0.2034, -0.1206],\n",
      "        [ 0.0155,  0.8748, -0.3244, -0.2943,  0.0160],\n",
      "        [ 0.2540,  1.1855, -0.8233, -0.4735,  0.0055],\n",
      "        [ 0.1698, -1.2351,  0.1965,  0.2963, -0.2878]], grad_fn=<MmBackward0>)\n",
      "Weight After Mask Filling  tensor([[ 0.1432,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.0383, -0.8364,    -inf,    -inf,    -inf],\n",
      "        [ 0.0155,  0.8748, -0.3244,    -inf,    -inf],\n",
      "        [ 0.2540,  1.1855, -0.8233, -0.4735,    -inf],\n",
      "        [ 0.1698, -1.2351,  0.1965,  0.2963, -0.2878]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "Raw Values to Offer for Attention  tensor([[ 0.6596, -0.3412,  0.6854,  0.4623],\n",
      "        [-0.3994,  0.1570,  0.5419,  0.6956],\n",
      "        [ 0.7482, -0.7134, -0.0972, -0.1077],\n",
      "        [ 0.9776, -0.8043,  0.2481,  0.1621],\n",
      "        [-1.1223,  0.5546, -1.0652, -0.6138]], grad_fn=<MmBackward0>)\n",
      "Final Weights for Value Accumulation  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6896, 0.3104, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2455, 0.5798, 0.1748, 0.0000, 0.0000],\n",
      "        [0.2293, 0.5819, 0.0781, 0.1108, 0.0000],\n",
      "        [0.2475, 0.0607, 0.2542, 0.2809, 0.1566]], grad_fn=<SoftmaxBackward0>)\n",
      "Accumulated Values for Attention   tensor([[ 0.6596, -0.3412,  0.6854,  0.4623],\n",
      "        [ 0.3309, -0.1865,  0.6409,  0.5347],\n",
      "        [ 0.0611, -0.1174,  0.4655,  0.4980],\n",
      "        [ 0.0855, -0.1316,  0.4924,  0.5203],\n",
      "        [ 0.4280, -0.3953,  0.0807,  0.0787]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "curr_token_seq= [10,12,24,3,6]\n",
    "ix= torch.tensor(curr_token_seq)\n",
    "attention_output2=attention_model(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08558792000000001\n"
     ]
    }
   ],
   "source": [
    "#wei => [0.2293, 0.5819, 0.0781, 0.1108, 0.0000]\n",
    "c1= 0.2293*.6596 + 0.5819*-0.3994 + 0.0781*.7482 + 0.1108*.9776 + 0.0000*-1.1223\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
